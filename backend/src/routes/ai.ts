import express from 'express'
import { readFile } from 'fs/promises'
import { join, resolve } from 'path'
import OpenAI from 'openai'
import Anthropic from '@anthropic-ai/sdk'
import { fetch, ProxyAgent } from 'undici'

const router = express.Router()

// ä»£ç†é…ç½®
const proxyUrl = process.env.HTTPS_PROXY || process.env.https_proxy || process.env.HTTP_PROXY || process.env.http_proxy

// åˆ›å»ºè‡ªå®šä¹‰ fetchï¼ˆæ”¯æŒä»£ç†ï¼‰
let customFetch: typeof fetch = fetch

if (proxyUrl) {
  const proxyAgent = new ProxyAgent(proxyUrl)
  console.log(`ğŸŒ AI è·¯ç”±ä½¿ç”¨ä»£ç†: ${proxyUrl}`)
  
  // åŒ…è£… fetch ä»¥ä½¿ç”¨ä»£ç†
  customFetch = ((url: any, options: any = {}) => {
    return fetch(url, { ...options, dispatcher: proxyAgent })
  }) as typeof fetch
}

// åœ¨ Docker ç¯å¢ƒä¸­ï¼Œå·¥ä½œç›®å½•æ˜¯ /app/backendï¼Œé¡¹ç›®æ ¹ç›®å½•æ˜¯ /app
// åœ¨æœ¬åœ°å¼€å‘ç¯å¢ƒä¸­ï¼Œå·¥ä½œç›®å½•æ˜¯ backendï¼Œé¡¹ç›®æ ¹ç›®å½•æ˜¯ backend çš„ä¸Šä¸€çº§
const PROJECT_ROOT = process.env.PROJECT_ROOT 
  ? resolve(process.env.PROJECT_ROOT)
  : resolve(process.cwd(), '..')

// AI æä¾›å•†ç±»å‹
type AIProvider = 'openai' | 'anthropic' | 'deepseek'

// å»¶è¿Ÿåˆå§‹åŒ–å®¢æˆ·ç«¯
let openaiClient: OpenAI | null = null
let anthropicClient: Anthropic | null = null
let deepseekClient: OpenAI | null = null

function getOpenAI(): OpenAI {
  if (!openaiClient) {
    console.log('åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯...')
    console.log('OPENAI_API_KEY:', process.env.OPENAI_API_KEY ? `å·²è®¾ç½® (${process.env.OPENAI_API_KEY.substring(0, 10)}...)` : 'æœªè®¾ç½®')
    console.log('OPENAI_BASE_URL:', process.env.OPENAI_BASE_URL || 'é»˜è®¤å®˜æ–¹')
    console.log('ä»£ç†:', proxyUrl || 'æœªè®¾ç½®')
    
    openaiClient = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY || '',
      baseURL: process.env.OPENAI_BASE_URL || undefined,
      fetch: customFetch as any,
    })
  }
  return openaiClient
}

function getAnthropic(): Anthropic {
  if (!anthropicClient) {
    console.log('åˆå§‹åŒ– Anthropic å®¢æˆ·ç«¯...')
    console.log('ANTHROPIC_API_KEY:', process.env.ANTHROPIC_API_KEY ? `å·²è®¾ç½® (${process.env.ANTHROPIC_API_KEY.substring(0, 10)}...)` : 'æœªè®¾ç½®')
    console.log('ANTHROPIC_BASE_URL:', process.env.ANTHROPIC_BASE_URL || 'é»˜è®¤å®˜æ–¹')
    console.log('ä»£ç†:', proxyUrl || 'æœªè®¾ç½®')
    
    anthropicClient = new Anthropic({
      apiKey: process.env.ANTHROPIC_API_KEY || '',
      baseURL: process.env.ANTHROPIC_BASE_URL || undefined,
      fetch: customFetch as any,
    })
  }
  return anthropicClient
}

function getDeepSeek(): OpenAI {
  if (!deepseekClient) {
    console.log('åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯...')
    console.log('DEEPSEEK_API_KEY:', process.env.DEEPSEEK_API_KEY ? `å·²è®¾ç½® (${process.env.DEEPSEEK_API_KEY.substring(0, 10)}...)` : 'æœªè®¾ç½®')
    console.log('ä»£ç†:', proxyUrl || 'æœªè®¾ç½®')
    
    deepseekClient = new OpenAI({
      apiKey: process.env.DEEPSEEK_API_KEY || '',
      baseURL: 'https://api.deepseek.com',
      fetch: customFetch as any,
    })
  }
  return deepseekClient
}

// è·å–å½“å‰ AI æä¾›å•†
function getAIProvider(): AIProvider {
  const provider = (process.env.AI_PROVIDER || 'deepseek').toLowerCase() as AIProvider
  return provider
}


// ç»Ÿä¸€çš„èŠå¤©æ¥å£
async function chat(systemPrompt: string, userMessage: string): Promise<string> {
  const provider = getAIProvider()
  
  console.log(`ä½¿ç”¨ AI æä¾›å•†: ${provider}`)
  
  if (provider === 'anthropic') {
    const model = process.env.ANTHROPIC_MODEL || 'claude-sonnet-4-20250514'
    console.log(`Anthropic æ¨¡å‹: ${model}`)
    
    const response = await getAnthropic().messages.create({
      model,
      max_tokens: 4096,
      system: systemPrompt,
      messages: [
        { role: 'user', content: userMessage },
      ],
    })
    
    const content = response.content[0]
    if (content.type === 'text') {
      return content.text
    }
    return 'æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå“åº”ã€‚'
  } else if (provider === 'deepseek') {
    // DeepSeekï¼ˆä½¿ç”¨ OpenAI å…¼å®¹æ¥å£ï¼‰
    const model = process.env.DEEPSEEK_MODEL || 'deepseek-chat'
    console.log(`DeepSeek æ¨¡å‹: ${model}`)
    
    const completion = await getDeepSeek().chat.completions.create({
      model,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userMessage },
      ],
      temperature: 0.7,
    })
    
    return completion.choices[0]?.message?.content || 'æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå“åº”ã€‚'
  } else {
    // OpenAI
    const model = process.env.OPENAI_MODEL || 'gpt-4'
    console.log(`OpenAI æ¨¡å‹: ${model}`)
    
    const completion = await getOpenAI().responses.create({
      model,
      input: [
        { role: 'developer', content: systemPrompt },
        { role: 'user', content: userMessage },
      ],
    })
    
    return completion.output_text || 'æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå“åº”ã€‚'
  }
}

// è¯»å–é¡¹ç›®æ–‡ä»¶ä½œä¸ºä¸Šä¸‹æ–‡
async function loadContext(): Promise<string> {
  const files = [
    'prompts/rules.md',
    'prompts/outline.md',
    'prompts/setting.md',
    'prompts/characters.md',
    'prompts/style_guide.md',
  ]

  const contexts: string[] = []

  for (const file of files) {
    try {
      const content = await readFile(join(PROJECT_ROOT, file), 'utf-8')
      contexts.push(`## ${file}\n${content}`)
    } catch (error) {
      console.warn(`æ— æ³•è¯»å– ${file}:`, error)
    }
  }

  return contexts.join('\n\n---\n\n')
}

// èŠå¤©æ¥å£
router.post('/chat', async (req, res) => {
  try {
    const { message, context } = req.body

    if (!message) {
      return res.status(400).json({ error: 'æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º' })
    }

    // åŠ è½½é¡¹ç›®ä¸Šä¸‹æ–‡
    const projectContext = await loadContext()

    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´åˆ›ä½œåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç”¨æˆ·åˆ›ä½œå°è¯´ã€‚

é¡¹ç›®è§„åˆ™å’Œè®¾å®šï¼š
${projectContext}

è¯·ä¸¥æ ¼éµå¾ªé¡¹ç›®çš„è§„åˆ™å’Œè®¾å®šï¼Œä¿æŒè§’è‰²æ€§æ ¼ä¸€è‡´æ€§ï¼Œéµå¾ªä¸–ç•Œè§‚è®¾å®šã€‚`

    const response = await chat(systemPrompt, message)

    res.json({
      content: response,
      updates: {
        files: [],
        actions: [],
      },
    })
  } catch (error) {
    console.error('AI èŠå¤©é”™è¯¯:', error)
    res.status(500).json({ error: 'AI å“åº”å¤±è´¥' })
  }
})

// ç”Ÿæˆç« èŠ‚
router.post('/generate-chapter', async (req, res) => {
  try {
    const { chapterNumber, context } = req.body

    if (!chapterNumber) {
      return res.status(400).json({ error: 'ç« èŠ‚ç¼–å·ä¸èƒ½ä¸ºç©º' })
    }

    const projectContext = await loadContext()
    const fullContext = context ? `${projectContext}\n\n${context}` : projectContext

    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´åˆ›ä½œåŠ©æ‰‹ã€‚è¯·ç”Ÿæˆç¬¬ ${chapterNumber} ç« çš„å†…å®¹ã€‚

é¡¹ç›®è§„åˆ™å’Œè®¾å®šï¼š
${fullContext}

è¯·ï¼š
1. ä¸¥æ ¼éµå¾ªé¡¹ç›®çš„è§„åˆ™å’Œè®¾å®š
2. ä¿æŒè§’è‰²æ€§æ ¼ä¸€è‡´æ€§
3. éµå¾ªä¸–ç•Œè§‚è®¾å®š
4. ç”Ÿæˆå®Œæ•´çš„ç« èŠ‚å†…å®¹
5. åœ¨å›å¤ä¸­è¯´æ˜éœ€è¦æ›´æ–°å“ªäº›æ–‡ä»¶ï¼ˆdatabaseã€åˆ—è¡¨æ–‡ä»¶ç­‰ï¼‰`

    const response = await chat(systemPrompt, `è¯·ç”Ÿæˆç¬¬ ${chapterNumber} ç« çš„å®Œæ•´å†…å®¹ã€‚`)

    res.json({
      content: response,
      updates: {
        files: [`prompts/chapters/${String(chapterNumber).padStart(3, '0')}_ç« èŠ‚å.md`],
        actions: ['åˆ›å»ºç« èŠ‚æ–‡ä»¶', 'æ›´æ–° database', 'æ›´æ–°åˆ—è¡¨æ–‡ä»¶'],
      },
    })
  } catch (error) {
    console.error('ç”Ÿæˆç« èŠ‚é”™è¯¯:', error)
    res.status(500).json({ error: 'ç”Ÿæˆç« èŠ‚å¤±è´¥' })
  }
})

// ä¿®æ”¹ç« èŠ‚
router.post('/modify-chapter', async (req, res) => {
  try {
    const { chapterNumber, modifications, context } = req.body

    if (!chapterNumber || !modifications) {
      return res.status(400).json({ error: 'ç« èŠ‚ç¼–å·å’Œä¿®æ”¹å†…å®¹ä¸èƒ½ä¸ºç©º' })
    }

    const projectContext = await loadContext()

    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´åˆ›ä½œåŠ©æ‰‹ã€‚è¯·æ ¹æ®è¦æ±‚ä¿®æ”¹ç¬¬ ${chapterNumber} ç« ã€‚

é¡¹ç›®è§„åˆ™å’Œè®¾å®šï¼š
${projectContext}

ä¿®æ”¹è¦æ±‚ï¼š
${modifications}

è¯·ï¼š
1. ä¿æŒä¸åŸæœ‰å†…å®¹çš„ä¸€è‡´æ€§
2. éµå¾ªé¡¹ç›®çš„è§„åˆ™å’Œè®¾å®š
3. åœ¨å›å¤ä¸­è¯´æ˜éœ€è¦æ›´æ–°å“ªäº›æ–‡ä»¶`

    const response = await chat(systemPrompt, `è¯·ä¿®æ”¹ç¬¬ ${chapterNumber} ç« ï¼š${modifications}`)

    res.json({
      content: response,
      updates: {
        files: [`prompts/chapters/${String(chapterNumber).padStart(3, '0')}_ç« èŠ‚å.md`],
        actions: ['æ›´æ–°ç« èŠ‚æ–‡ä»¶', 'æ›´æ–° database', 'æ›´æ–°åˆ—è¡¨æ–‡ä»¶'],
      },
    })
  } catch (error) {
    console.error('ä¿®æ”¹ç« èŠ‚é”™è¯¯:', error)
    res.status(500).json({ error: 'ä¿®æ”¹ç« èŠ‚å¤±è´¥' })
  }
})

// æ£€æŸ¥ä¸€è‡´æ€§
router.post('/check-consistency', async (req, res) => {
  try {
    // TODO: å®ç°ä¸€è‡´æ€§æ£€æŸ¥é€»è¾‘
    res.json({
      content: 'ä¸€è‡´æ€§æ£€æŸ¥åŠŸèƒ½å¼€å‘ä¸­...',
      updates: {
        files: [],
        actions: [],
      },
    })
  } catch (error) {
    console.error('æ£€æŸ¥ä¸€è‡´æ€§é”™è¯¯:', error)
    res.status(500).json({ error: 'æ£€æŸ¥ä¸€è‡´æ€§å¤±è´¥' })
  }
})

// è·å– AI é…ç½®ï¼ˆç”¨äºè°ƒè¯•ï¼‰
router.get('/config', (req, res) => {
  res.json({
    provider: process.env.AI_PROVIDER || 'deepseek (é»˜è®¤)',
    deepseek: {
      apiKey: process.env.DEEPSEEK_API_KEY ? 'å·²è®¾ç½®' : 'æœªè®¾ç½®',
      baseURL: 'https://api.deepseek.com',
      model: process.env.DEEPSEEK_MODEL || 'deepseek-chat (é»˜è®¤)',
    },
    openai: {
      apiKey: process.env.OPENAI_API_KEY ? 'å·²è®¾ç½®' : 'æœªè®¾ç½®',
      baseURL: process.env.OPENAI_BASE_URL || 'é»˜è®¤å®˜æ–¹',
      model: process.env.OPENAI_MODEL || 'gpt-4 (é»˜è®¤)',
    },
    anthropic: {
      apiKey: process.env.ANTHROPIC_API_KEY ? 'å·²è®¾ç½®' : 'æœªè®¾ç½®',
      baseURL: process.env.ANTHROPIC_BASE_URL || 'é»˜è®¤å®˜æ–¹',
      model: process.env.ANTHROPIC_MODEL || 'claude-sonnet-4-20250514 (é»˜è®¤)',
    },
  })
})

export default router
